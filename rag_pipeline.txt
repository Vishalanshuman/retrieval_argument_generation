import os
from dotenv import load_dotenv
from rag.models.document_creator import DocumentCreator
from  rag.models.embeddings import EmbeddingModel
from rag.extraction.pdf_extractor import PDFExtractor
from rag.qa.retrieval_qa import RetrievalQAChain
from rag.models.chat_history import ChatHistory
from rag.utils.logger import Logger
from rag.config.settings import Settings

load_dotenv()

logger = Logger(log_name="rag_application.log").get_logger()

def main():
    """
    Main function to run the RAG application pipeline.
    """
    try:
        logger.info("Starting RAG application pipeline.")
        setting = Settings()

        chat_history = ChatHistory()
        chat_id = "unique_chat_id"  # Unique chat session identifier
        embedding_model = setting.embedding_model
        qa_model = setting.model_name

        document_extractor = PDFExtractor()
        text = document_extractor.extract_text_from_all_pdfs()

        document_creator = DocumentCreator()
        documents = document_creator.create_documents_from_text(text)
        logger.info("Documents created successfully from PDF.")

        embeddings = EmbeddingModel(model_name=embedding_model)
        index_document = embeddings.index_documents(documents)
        vectorstore = embeddings.get_vectorstore()
        logger.info("Document embeddings generated and indexed successfully.")

        qa_chain = RetrievalQAChain(model_name=qa_model, vectorstore=vectorstore)
        qa_chain.setup_qa_chain()
        logger.info("Retrieval QA chain setup successfully.")

        # Initial question
        question = "What experience does this candidate have in software development?"
        previous_history = chat_history.retrieve_chat_history(chat_id)  # Retrieve the last interactions

        # Combine previous history with the new question
        if previous_history:
            conversation_context = "\n".join([item['message'] for item in previous_history])
            full_question = f"{conversation_context}\n{question}"
        else:
            full_question = question

        # Ask the question using the QA chain, considering the previous history
        answer = qa_chain.ask_question(full_question)
        logger.info(f"Question: {question}")
        logger.info(f"Answer: {answer}")

        # Upsert the question and answer along with their embeddings into chat history
        chat_history.upsert_message(chat_id, question, embeddings)
        chat_history.upsert_message(chat_id, answer, embeddings)

        # Retrieve updated chat history for this chat_id
        updated_history = chat_history.retrieve_chat_history(chat_id)
        logger.info(f"Updated chat history for {chat_id}: {updated_history}")

        # Display the answer
        print(f"Answer to the question '{question}': {answer}")

        # Simulate asking another question (to demonstrate context)
        new_question = "What kind of projects has this candidate worked on?"
        previous_history = chat_history.retrieve_chat_history(chat_id)  # Retrieve history again

        # Combine the previous history with the new question
        if previous_history:
            conversation_context = "\n".join([item['message'] for item in previous_history])
            full_question = f"{conversation_context}\n{new_question}"
        else:
            full_question = new_question

        # Ask the next question using the QA chain with the history as context
        new_answer = qa_chain.ask_question(full_question)
        logger.info(f"New Question: {new_question}")
        logger.info(f"New Answer: {new_answer}")

        # Update chat history again
        chat_history.upsert_message(chat_id, new_question, embeddings)
        chat_history.upsert_message(chat_id, new_answer, embeddings)

        # Display the new answer
        print(f"Answer to the new question '{new_question}': {new_answer}")

    except Exception as e:
        logger.error("An error occurred in the RAG application pipeline.", exc_info=True)
if __name__ == "__main__":
    main()
